{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "157ea9f4",
   "metadata": {},
   "source": [
    "# STEP 2: Convert Text â†’ Numbers (Tokenization & Vocabulary)\n",
    "Neural Network can not understand the text it only understans the numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c7bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv(\"training.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62d92ca",
   "metadata": {},
   "source": [
    "## Define a Simple Tokenizer\n",
    "Below function will do this : \n",
    "I am Tirth Patel  -- > ['i', 'am', 'tirth', 'patel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e98827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    return text.split()\n",
    "\n",
    "print(tokenize(\"I am Tirth Patel\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bdd5d9",
   "metadata": {},
   "source": [
    "## Build Vocabulary from Training Data\n",
    "\n",
    "ðŸ“Œ Why special tokens? \n",
    "- `<PAD>` : for padding\n",
    "- `<UNK>` : unseen words in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc3d4721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 15214\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_counter = Counter()\n",
    "\n",
    "for sentance in train_df[\"text\"]:\n",
    "     tokens = tokenize(sentance)\n",
    "     word_counter.update(tokens)\n",
    "     \n",
    "# Special tokens\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "UNK_TOKEN = \"<UNK>\"\n",
    "\n",
    "vocab = {\n",
    "    PAD_TOKEN: 0,\n",
    "    UNK_TOKEN: 1\n",
    "}\n",
    "\n",
    "for word,_ in word_counter.items():\n",
    "     vocab[word] = len(vocab)\n",
    "     \n",
    "print(\"Vocabulary size:\",len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafbafdd",
   "metadata": {},
   "source": [
    "## Convert Text to Numerical Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "708f3ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 661]\n"
     ]
    }
   ],
   "source": [
    "def encode_sentence(sentance , vocab) :\n",
    "     tokens = tokenize(sentance)\n",
    "     return [vocab.get(token, vocab[UNK_TOKEN]) for token in tokens]\n",
    "\n",
    "print(encode_sentence(\"I feel happy\", vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb224c07",
   "metadata": {},
   "source": [
    "## Padding (VERY IMPORTANT)\n",
    "Neural networks need same-length inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8719e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 50\n",
    "\n",
    "def pad_suquence(seq , max_len) :\n",
    "     if len(seq) < max_len:\n",
    "        return seq + [vocab[PAD_TOKEN]] * (max_len - len(seq))\n",
    "     else:\n",
    "          return seq[:max_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbd3637",
   "metadata": {},
   "source": [
    "## Final Encoded Dataset (Training Only) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c45ee82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "X_train = [\n",
    "     pad_suquence(encode_sentence(text , vocab) , MAX_LEN)\n",
    "     for text in train_df['text']\n",
    "]\n",
    "\n",
    "y_train = train_df['label'].values\n",
    "print(X_train[0])\n",
    "print(len(X_train[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d8442d",
   "metadata": {},
   "source": [
    "## What Youâ€™ve Achieved\n",
    "Implemented custom tokenization, vocabulary construction, sequence encoding, and padding for NLP tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dda1ce",
   "metadata": {},
   "source": [
    "# STEP 3: PyTorch Dataset & DataLoader (Industry Standard)\n",
    "â— Goal of this step\n",
    "> Convert your processed data into a format that PyTorch models can train on.\n",
    "---\n",
    "## Why Dataset & DataLoader?\n",
    "Instead of loading everything at once, PyTorch:\n",
    "- Loads data in batches\n",
    "- Shuffles training data\n",
    "- Works efficiently on CPU / GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561d9eff",
   "metadata": {},
   "source": [
    "## Convert Data to PyTorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4947ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce92e0af",
   "metadata": {},
   "source": [
    "## Create a Custom Dataset Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9d029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset) :\n",
    "     def __init__(self , texts , labels) :\n",
    "          self.texts = torch.tensor(texts, dtype=torch.long)\n",
    "          self.labels = torch.tensor(labels ,dtype=torch.long )\n",
    "     \n",
    "     def __init__(self) :\n",
    "          return len(self.labels)\n",
    "\n",
    "     def __getitem__(self , idx) :\n",
    "          return self.texts[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cefdd7",
   "metadata": {},
   "source": [
    "## Create Training & Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3333c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EmotionDataset(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
